---
title: "Illustrating negative binomial distributions"
author: 
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    social: menu
    source_code: embed
runtime: shiny
---
Home
===

```{r global, include=FALSE}

library(MASS) # for neg binomial analysis

lwd.=3

 my_dnbinom=function(x,mu,alpha){
  m = mu
  k = 1/alpha
  # lgamma is log(gamma)
  a = lgamma(k+x)-lgamma(k)-lgamma(x+1)
  b = x*log(m/(m+k))
  c = -k*log(1+m/k)
  prob = exp(a+b+c)
  prob[x<0] = 0
  prob[prob>1] = 1
  prob[prob<0] = 0
  return(prob)
}

# check
# dnbinom(   1, size=2,   mu=3)
# my_dnbinom(1, alpha=1/2,mu=3)

##################################################################################
# R has built-in random number generators for the binomial distribution,
# but they are expressed in different form than the form in the Lloyd-Smith
# PLoS paper. This function translates the mu and alpha parameters
# into the format needed by R to generate the NB random numbers
##################################################################################
my_rnbinom=function(n,mu,alpha){
  size = 1/alpha          # so now we can just enter alpha this is converted to 1/ alpha
  prob = size/(mu+size)   # so now we can enter mu the mean and that is converted to prob
  return(rnbinom(n,size=size,prob=prob))
}

GenerateMultivariatePoisson<-function(p, samples, R, lambda){
  normal_mu=rep(0, p)
  normal = mvrnorm(samples, normal_mu, R)
  unif=pnorm(normal)
  pois=t(qpois(t(unif), lambda))
  return(pois)
}

  mvrnorm <- function(n = 1, mu = 0, Sigma) {
    nvars <- nrow(Sigma)
    # nvars x n matrix of Normal(0, 1)
    nmls <- matrix(rnorm(n * nvars), nrow = nvars)
    # scale and correlate Normal(0, 1), "nmls", to Normal(0, Sigma) by matrix mult
    # with lower triangular of cholesky decomp of covariance matrix
    scaled_correlated_nmls <- t(chol(Sigma)) %*% nmls
    # shift to center around mus to get goal: Normal(mu, Sigma)
    samples <- mu + scaled_correlated_nmls
    # transpose so each variable is a column, not
    # a row, to match what MASS::mvrnorm() returns
    t(samples)
  }
  

nb.power <- function(n=220, k=1.3, mu0=1, eff=0.65, drop1=.1, drop2=.1, fup=1) {
  
  mu1 <- eff*mu0
  
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  # n=220; alpha=1.3; mu0=1; mu1=.65; drop1=.01; drop2=.01; fup=1
 
  dose <- c(rep("placebo",n),rep("trt",n)) # 50:50 split of patients
  
  mu   <- c(rep(mu0,n), rep(mu1,n))    # rates in two arms

  drop <- c(rep(drop1,n), rep(drop2,n)) # }# tr discontinuation rates
  
  f    <- - rexp(2*n) / log(1-drop)
  
  length <- ifelse(f > fup, fup, f)        # curtail at follow up time 
  
  y  <-  rnbinom(n*2,  prob=1/(1+ mu*length* k),        size=1/k)  +   # on treatment events
         rnbinom(n*2,  prob=1/(1+ mu0*(fup-length)*k),  size=1/k)      # accounting for any off treat. 
  
  # assume no is lost to the study but can discontinue treatment
  lfup     <- log(fup)         # exposure log(fup) for everyone, that is fup year
  logleng  <- rep(lfup, n*2)   #  
  
  # analyse with neg. binomial model
  x <- summary(MASS::glm.nb(y~dose+offset((logleng))))
 
  # collect p-values
  p <-  x$coefficients["dosetrt","Pr(>|z|)"]
  
  return(p)
  
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# correlated poisson function
 
library(lme4)
 
po.cor.power <- function(n=22, r=.75, mu0=10, eff.p=.75) { # r correlation mu0 placebo rate, mu1 expected change in rate
   
  #n=22; r=.75; mu0=10; eff.p=.75
  # 1. create correlated poisson
  # 2. analyse many times and examine

  L1 <- mu0
  L2 <- mu0*eff.p
  
  # generate correlated poisson ref: https://thomasward.com/simulating-correlated-data/
  
  # Sample correlated N(0, 1) distributions from a multivariate normal distribution.
  # Transform them to correlated Uniform(0, 1) distributions with the normal CDF.
  # Transform them to any correlated probability distribution you desire with that probability distribution’s inverse CDF.
  
  Sigma <- matrix(c(1, r, r, 1), 2, 2)
  #Sigma
  

  p2 <- mvrnorm(n, Sigma = Sigma)   # correlated continuous  # see function in global area!
  
  U <- pnorm(p2, mean = 0, sd = 1)  # correlated uniform
  
  pp1 <- qpois(U[, 1], L1)          # correlated poisson
  pp2 <- qpois(U[, 2], L2)          # correlated poisson
  
  # create a data frame
  my_data <- data.frame( 
    group = rep(c("A.before", "B.after"), each = n),
    counts = c(pp1,  pp2),
    ID=rep(1:n,2)
  )
  
  # analyse
  # https://stats.stackexchange.com/questions/71194/fitting-a-poisson-distribution-with-lme4-and-nlme
  # https://stats.stackexchange.com/questions/27869/fitting-a-poisson-glm-mixed-model-with-a-random-slope-and-intercept
   
  A <- glmer(counts ~ group + (1|ID), data=my_data, family="poisson")
 # B <- glmer(counts ~ 1     + (1|ID), data=my_data, family="poisson")  # dont use LRT to speed up sims
#  p <- anova(A,B)
#  mix <-  p$`Pr(>Chisq)`[2]
  
  x <- summary(A)
  mix <- summary(A)$coeff[2,"Pr(>|z|)"]  # to speed up simulations dont use LRTtest but wald
  
  rate.reduction <- exp(x$coefficients[2,1])
  
  intercept <- exp( x$coefficients[1,1])
  beta      <- exp( x$coefficients[2,1])
  
  x1 <- pp2 - pp1                                     # post - pre
  
  w <- wilcox.test(x=x1, paired=FALSE, correct=FALSE, conf.int=TRUE  ,conf.level = 0.95)
   
  wil <- w$p.value
  wile <- w$estimate[1][[1]]
  
  t.t <- t.test(x=x1, paired=FALSE)$p.value # t.test(x1)$p.value 
   
  signed_rank = function(x) sign(x) * rank(abs(x))
  ttor <- t.test(signed_rank(x1))$p.value
  
  # wilcox.test(x1)
  # t.test(signed_rank(x1))
  
  #lets capture SD of differences
  sdd <- sd(x1)
  
  #newList <- list("glmer" = mix , "Wilcoxon signed rank test" = wil,
              #    "t.test"=t.t, "rate reduction"= rate.reduction, "intercept"=intercept, "beta"=beta,
               #   "ttest on ranks"=ttor, "sd of diff"=sdd)
  #return(newList)
  
  
  
  c(rate.reduction,mix , wil,t.t,  ttor,intercept, beta ,sdd, wile)
  
}


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```


Column {.sidebar}
-----------------------------------------------------------------------

Count data analysis is explored...

```{r}

library(shiny)
library(utf8)

sliderInput('mu', 'Common  \u03BC', value=1.5,
              min = 1, max = 25, step=.5, ticks=F)

sliderInput('alpha_a', '\u03B1 for red curve', value = c(0.8),
              min = 0, max = 5 ,step=0.01, ticks=F)

sliderInput('alpha_b', '\u03B1 for dark blue curve', value = c(0.8),
              min = 0, max = 5 ,step=0.01, ticks=F)

sliderInput('alpha_d', '\u03B1 for purple curve', value = c(0.8),
              min = 0, max = 5 ,step=0.01, ticks=F)

sliderInput('sims', 'Simulations (chart 2)', 50000,
              min = 50000, max = 500000,step=50000,ticks=F)

sliderInput('x_range', 'Plot x-range', value = c(0,10),
        min = 0, max = 80,step=5,ticks=F)

sliderInput('y_range', 'Plot y-range', value = c(0,.4),
        min = 0, max = 1,step=.05,ticks=F)

 

```

This page of the app uses  $\alpha$. 

$\alpha$ takes on positive rational values, rarely above 4 (Hilbe page 190)

When  $\alpha$ approaches 0, k is infinite and Poisson emerges (move red $\alpha$ slider to 0).

When  $\alpha$ > 1, k < 1 highly leads to over dispersed data ($\alpha$ big).

$\alpha$ = 1/k

k = 1/ $\alpha$
 

Column {data-width=400, height=300}
-----------------------------------------------------------------------
### Chart 1


```{r}

renderPlot({
  
 
require("sfsmisc")
#set.seed(28754) # set random number seed for reproducibilty of results

##################################################################################
# Define the Negative Binomial probability density function, with parameters
# mu and alpha
# The mean of this NB distribution is mu, and variance is sigma^2=mu+alpha*mu^2
##################################################################################

##################################################################################
# Now let's try out the NB density function, and overlay the Poisson
# distribution with the same mean
##################################################################################
#mult.fig(2) # divide the plotting area up into 2 (one up and one down)

# mu = sample(1:25,1)
# alpha_a = 0.1
# alpha_b = .01
# alpha_d = 1

  mu = input$mu
  alpha_a = input$alpha_a
  alpha_b =  input$alpha_b
  alpha_d =  input$alpha_d
  
  low =  input$x_range[1]
  high=  input$x_range[2]
  xmax = high
  
  ymax = input$y_range[2]

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  # if else turn neg binomial into poisson if alpha =0
  x=c(-0.0001,seq(0,xmax,1))
  
  y =          dpois(x,mu)
   
  if(alpha_a==0) {
  yb =          dpois(x,mu)
  }else{
  yb=     my_dnbinom(x,mu,alpha_a)
  }
  
  if(alpha_b==0){
  yc =          dpois(x,mu)
  }else{
  yc=     my_dnbinom(x,mu,alpha_b)
  }
  
  if(alpha_d==0){
  yd =          dpois(x,mu)
  }else{
  yd=     my_dnbinom(x,mu,alpha_d)
  }
  
  nor <-       dnorm(x, mu, sqrt(mu))


  x=append(0,x)  
  y=append(0,y)
  yb=append(0,yb)
  yc=append(0,yc)
  yd=append(0,yd)
  nor=append(0,nor)
  
  l = !is.na(y+yb+yc+yd+nor)
  
  plot(x[l],y[l],ylim=c(0,ymax),xlim=c(low,xmax),type="l",lwd=lwd.,xlab="x",
       ylab="prob(x)",main="Probability distributions")
  
  lines(x[l],yb[l], col=2,lwd=lwd.,type="l")
  lines(x[l],yc[l], col=4,lwd=lwd.,type="l")
  lines(x[l],nor[l],col=5,lwd=lwd.,type="l")
  lines(x[l],yd[l], col=6,lwd=lwd.,type="l")
   
  # https://stackoverflow.com/questions/6044800/adding-greek-character-to-axis-title
  apois = paste("Poisson \u03BC=",mu,sep="")
  anegbinom_a = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_a,sep="")
  anegbinom_b = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_b,sep="")
  anegbinom_c = paste("Normal \u03BC=",   mu," \u03C3=sqrt(",mu,")",sep="")
  anegbinom_d = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_d,sep="")
  
  
  legend("topright",col=c(1,2,4,6,5),legend=c(apois,anegbinom_a,anegbinom_b, anegbinom_d, anegbinom_c),
         lwd=lwd.,bty="n")
 }
)




```


### Chart 2

```{r}

renderPlot({
  

    n=input$sims
    
    mu = input$mu
    alpha_a =  input$alpha_a
    alpha_b =  input$alpha_b
    alpha_d =  input$alpha_d
    
    low =  input$x_range[1]
    high=  input$x_range[2]
    xmax = high
    
    ymax = input$y_range[2]
    
    z  =      rpois(n,mu)
    zb = my_rnbinom(n,mu,alpha_a)
    zc = my_rnbinom(n,mu,alpha_b)
    zd =      rnorm(n,mu,sqrt(mu))
    ze = my_rnbinom(n,mu,alpha_d)
    
    a=hist(z, plot=F,breaks=seq(-1.5,n+.5,1))
    b=hist(zb,plot=F,breaks=seq(-1.5,n+.5,1))
    c=hist(zc,plot=F,breaks=seq(-1.5,n+.5,1))
    d=hist(zd,plot=F,breaks=200)
    e=hist(ze,plot=F,breaks=seq(-1.5,n+.5,1))
    
    atitle = paste("Distributions of",n,"random numbers")
    
    plot(a$mids,a$density,type="s",lwd=lwd.,col=1,ylim=c(0,ymax),main=atitle,xlim=c(low,xmax),
         xlab="x",ylab="Fraction falling within each bin")
    
    lines(b$mids,b$density,type="s",lwd=lwd.,col=2)
    lines(c$mids,c$density,type="s",lwd=lwd.,col=4)
    lines(d$mids,d$density,type="s",lwd=lwd.,col=5)
    lines(e$mids,e$density,type="s",lwd=lwd.,col=6)
    
    apois = paste("Poisson \u03BC=",mu,sep="")
    anegbinom_a = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_a,sep="")
    anegbinom_b = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_b,sep="")
    anegbinom_c = paste("Normal \u03BC=",   mu," \u03C3=sqrt(",mu,")",sep="")
    anegbinom_d = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_d,sep="")
    
    legend("topright",col=c(1,2,4,6,5),legend=c(apois,anegbinom_a,anegbinom_b, anegbinom_d, anegbinom_c),
           lwd=lwd.,bty="n")


})


 
```

Column {data-width=400}
-------------------------------------

### Chart 3

```{r}


renderPlot({
  
    mu = input$mu
  alpha_a = input$alpha_a
  
  
  low =  input$x_range[1]
  high=  input$x_range[2]
  xmax = high
  
  ymax = input$y_range[2]

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 
  xx <- c(seq(0,xmax,1))

  yb = dpois(xx,mu)
  
  par(mar=c(2.1,4.1,4.1,4.1))
      
  barplot(yb, xlim=c(0,high+2), ylab = "Percent", xlab="x", col='black', ylim=c(0,ymax),
          main = paste("Poisson \u03BC=", mu, ", based on common \u03BC",sep=""),
          names.arg= as.character(xx))
})

```

### Chart 4

```{r}

 
    renderPlot({
  
    mu = input$mu
  alpha_a = input$alpha_a
  
  
  low =  input$x_range[1]
  high=  input$x_range[2]
  xmax = high
  
  ymax = input$y_range[2]

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 
  xx <- c(seq(0,xmax,1))

  if(alpha_a==0) {
  yb =          dpois(xx,mu)
  }else{
  yb=     my_dnbinom(xx,mu,alpha_a)
  }
  
  par(mar=c(2.1,4.1,4.1,4.1))
      
  barplot(yb, xlim=c(0,high+2), ylab = "Percent", xlab="x", col='red',
          ylim=c(0,ymax),
          main =  paste("Negative Binomial \u03BC=",mu," \u03B1=",alpha_a,", based on common mean and red curve \u03B1",sep=""),
          names.arg= as.character(xx))
  
})
    
    
   


```

Notes
===

cor neg binomial not working
explain corr poisson approach <- many packages
understand neg binomial rct rnbinom inputs
gamma - see basics plot

When $\alpha$ = 1, the negative binomial distribution takes the form of a
geometric distribution, which is the discrete correlate of the continuous negative
exponential distribution. 
The negative binomial distribution with $\alpha$ = 0 is Poisson.
As the mean increases, the probability of
a zero decreases, and the more the shape approximates a Gaussian distribution.
As the Poisson mean gets larger it approaches normality, the negative binomial distribution does not respond to larger mean values in that manner. 


The binomial distribution describes the number of r successes in n trials.

The geometric distribution describes the number of failures before the first success, r.

The negative binomial distribution describes the number of failures before the rth success. (Hilbe page 194)

Confusingly, the term ‘dispersion parameter’ can refer to either k or $\alpha$ ; other terms for k include ‘shape
parameter’ and ‘clustering coefficient’.

The only restriction placed on  $\alpha$ is that it take positive rational values,
rarely above 4 (Hilbe page 190)

 

Underdispersed data are assigned the minimum value of $\alpha$, corresponding to k going to infinity.



Accordingly, all calculations in this study were conducted using $\alpha$, but all results and discussion
are posed in terms of k?

In this study ML estimation was conducted for the parameter $\alpha$,
but results are reported in terms of k = 1/ $\alpha$ because k is more
familiar to epidemiologists and ecologists. Estimates of $\alpha$ were
restricted to positive values, because the allowed range for k was (0,infinity). 


file:///C:/Users/Lenovo/OneDrive/Documents/PAPERS/COUNT%20DATA/TRISTAN%20study%20Keene%202007.pdf
thy dispersion is alpha in this paper example figure 1

 The larger the gamma shape parameter, the more dispersed is the distribution
 
 The dispersion parameter k is commonly used as an inverse measure of aggregation in biological count data



Negative binomial power
====

Column {.sidebar}
-----------------------------------------------------------------------



```{r}

 
# jscode <- "shinyjs.refresh = function() { history.go(0); }"
# 
# actionButton(jscode, "Refresh")
# 
# observeEvent(input$reset, {
# 
# })

 
 

sliderInput('N', 'Patients per arm', value=220,
              min = 10, max = 10000, step=5, ticks=F)

sliderInput('mu0', 'Placebo mean rate \u03BC', value=1,
              min = 0.1, max = 25, step=.05, ticks=F)

sliderInput('eff', 'Hypothesised treatment effect ', value=.75,
              min = 0.1, max = 25, step=.05, ticks=F)

sliderInput('k', '1/\u03B1 the heterogeneity (ancillary) parameter', value = c(1.3),
              min = 0, max = 5 ,step=0.01, ticks=F)

sliderInput('d1', 'Placebo discontinuation prob', value = c(0.1),
              min = 0, max = .5 ,step=0.05, ticks=F)

sliderInput('d2', 'Treatment discontinuation prob', value = c(0.1),
              min = 0, max = .5 ,step=0.05, ticks=F)

sliderInput('fup', 'Follow up (yrs)', value = c(1),
        min = 0, max = 10, step=1,ticks=F)
 
sliderInput('sims2', 'Power simulations', value= 500,
              min = 500, max = 10000, step= 500, ticks=F)
 
 

```

Row {data- height=650}
-----------------------------------------------------------------------
### Power will appear here iminently...be patient...
  
```{r, eval=TRUE}

reactive({
  
cat(paste0("A RCT with 1:1 randomisation is being planned to investigate an intervention on the rate of asthma exacerbations with ",input$N," patients per arm.\n"))

cat(paste0("The negative binomial model will be used as patient heterogeneity of exacerbations beyond that captured by patient level covariates is expected.\nWe will use the natural log of duration of follow up time as an offset variable, the duration of follow up, ",input$fup, " will be the planned duration of follow up for all patients (see slider)."))

cat(paste0("\nk is the dispersion parameter value of " ,input$k," this is the same as 1/alpha So alpha is ",1/input$k,". The rate for placebo is ",input$mu0," events per patient year of follow up.\nThe treatment effect hypothesised is  ",input$eff, ". \nDrop out probabilities for treatment discontinuation and follow up period (in years) are " ,input$d1, " and " ,input$d2," respectively. \nWe assume a constant exponential hazard rate over time for treatment discontinuation with ",input$d1," and ",input$d2,", the percentages of patients\noff treatment by follow up time in years in active and placebo. \nNo further treatment effect versus placebo is assumed during off treatment, that is ",input$mu0," events per patient year is assumed for patients after treatment discontinuation in treated and placebo.\n"))

cat(paste0("\nThe power estimate is..."))
})
  
 

reactive({
  
res <- replicate( input$sims2, 
      nb.power(n=input$N, k=input$k, mu0=input$mu0, eff=input$eff, drop1=input$d1, drop2=input$d2, fup=input$fup)) 
mean(res<0.05)

})


```
 
Row {data-height=350}
-------------------------------------
   
### A typical dataset that can be expected

```{r}

 renderPlot({
  
 n=input$N
 k=input$k
 mu0=input$mu0
 eff=input$eff
 drop1=input$d1
 drop2=input$d2
 fup=input$fup
 
 mu1 <- eff*mu0
 
  dose <- c(rep("placebo",n),rep("trt",n))
  mu   <- c(rep(mu0,n),rep(mu1,n))
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  drop <- c(rep(.1,n),rep(.1,n))

  f <- - rexp(2*n) / log(1-drop)
  length <- ifelse(f>1,1,f)
 
  y <-  rnbinom(n*2,  p=1/(1+ mu*length* k),      size=1/k)  +
        rnbinom(n*2,  p=1/(1+ mu0*(1-length)*k),  size=1/k)

  logleng  <- rep(0, n*2)

  #addmargins(table( y,  dose))

 # d <- cbind.data.frame(dose, mu, length, y, logleng)
#  summary(MASS::glm.nb(y~dose+offset((logleng)), data=d))

  trt <- y[dose %in% "trt"]
  pla <- y[!dose %in% "trt"]
# examine
# par(mfrow=c(1,2))
# trt %>% table %>% barplot() #quick and dirty
# trt %>% table %>% prop.table
# pla %>% table %>% barplot() #quick and dirty
# pla %>% table %>% prop.table
# par(mfrow=c(1,1))
upp <- ceiling(max(prop.table(table(y))) * 100 ) 
par(mfrow=c(1,2))
data_perc <- t(prop.table(table(trt))) * 100    # Convert data to probability table
barplot(data_perc, ylab = "Percent", main ="Treated", ylim=c(0,upp ))     
data_perc <- t(prop.table(table(pla))) * 100    # Convert data to probability table
barplot(data_perc, ylab = "Percent", main ="Placebo", ylim=c(0,upp ))     
par(mfrow=c(1,1))

})



```   
 
   
### A typical result that can be expected, theta is synonymous with $\alpha$

```{r}

 renderPrint({
  
 n=input$N
 k=input$k
 mu0=input$mu0
 eff=input$eff
 drop1=input$d1
 drop2=input$d2
 fup=input$fup
 
 mu1 <- eff*mu0
 
  dose <- c(rep("placebo",n),rep("trt",n))
  mu   <- c(rep(mu0,n),rep(mu1,n))
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  drop <- c(rep(.1,n),rep(.1,n))

  f <- - rexp(2*n) / log(1-drop)
  length <- ifelse(f>1,1,f)
 
  y <-  rnbinom(n*2,  p=1/(1+ mu*length* k),      size=1/k)  +
        rnbinom(n*2,  p=1/(1+ mu0*(1-length)*k),  size=1/k)

  logleng  <- rep(0, n*2)

  #addmargins(table( y,  dose))

  d <- cbind.data.frame(dose, mu, length, y, logleng)
  print (f <- summary(MASS::glm.nb(y~dose+offset((logleng)), data=d)))
  
cat(paste0("\nPlacebo rate ",round(exp(f$coef[1]),4)," and multiplicative treatement effect of ",round(exp(f$coef[2]),4),""))
    
})
  
``` 

Poisson paired counts
====

Column {.sidebar}
-----------------------------------------------------------------------

```{r}


sliderInput('N.p', 'Patients per arm', value=22,
              min = 10, max = 200, step=5, ticks=F)

sliderInput('mu0.p', 'Placebo mean rate \u03BC', value=10,
              min = 0.1, max = 25, step=.05, ticks=F)

sliderInput('eff.p', 'Hypothesised treatment effect ', value=.75,  # 1/2 ing to doubling
              min = 0.5, max = 2, step=.05, ticks=F)

sliderInput('r', 'Correlation', value = c(.20),
              min = -1, max = 1 ,step=0.05, ticks=F)
 
sliderInput('sims.p', 'Power simulations', value= 10,
              min = 100, max = 1000, step= 100, ticks=F)
 

```

Row {data-height=275}
-----------------------------------------------------------------------

### Single arm pre post study design simulation
  

```{r, eval=TRUE}

 
reactive({
  
cat(paste0("This is an example of paired study design in which the outcome measure is counts of events and which does not use a concurrent control, so is not a great study design. \nNevertheless, we have ",input$N.p," subjects assessed before and after an intervention. The Poisson model will be used, the observation time is the same for the the pre and post periods.\n"))

cat(paste0("We will simulate the data based on a expected rate before the intervention of, ",input$mu0.p, " and an hypothesised effect of intervention ",input$eff.p,", so a hypothesised mean rate of ",input$mu0.p*input$eff.p," for the intervention.\nWe also take into account the correlation between obervations for the same individual, the starting value is " ,input$r,".\n")) 

cat(paste0("\nWe report the average p-value from a mixed Poisson model and the power, Wilcoxon signed rank test power, T test power, T test on ranks power, intercept, treatment effect and SD of differences. \nWe also quote the theoretical SD of differences."))

cat(paste0("\nTo generate correlated Poisson variables we..."))
cat(paste0("\n1) Sample two correlated N(0, 1) distributions from a multivariate normal distribution."))
cat(paste0("\n2) Transform them to correlated Uniform(0, 1) distributions using the normal CDF."))
cat(paste0("\n3) Transform them to the desired correlated probability distribution desired using that probability distribution’s inverse CDF!"))
 
})


``` 

Row {data-height=250}
-----------------------------------------------------------------------

### Results


```{r, eval=TRUE}

reactive({
  
  res <- replicate(input$sims.p, 
                   po.cor.power(n=input$N.p, r=input$r, mu0=input$mu0.p,  eff.p=input$eff.p ) )  

  #print(res)
  x <- NULL
  x <- t((res))
  x <- as.data.frame(x)
  alpha=0.05
 # cat("Mean treatment effect\n")
#  print(mean( unlist(x[,"V1"]))   )  
  # cat("Median mixed Poisson p-value\n")
  # print(median( unlist(x[,"V2"]))  )                                    # median mix p-value
  #   cat("\nPower mixed Poisson model\n")
  # print(table( unlist(x[,"V2"])< alpha)/input$sims.p)                   # power mix model
  # cat("\nWilcoxon signed rank test power\n")
  # print(table( unlist(x[,"V3"])< alpha)/input$sims.p )                  # Wilcoxon signed rank test power
  #  cat("\nT test power\n")
  # print(table( unlist(x[,"V4"])< alpha)/input$sims.p )                  # ttest power
  #  cat("\nT test on ranks power\n")
  # print(table( unlist(x[,"V5"])< alpha)/input$sims.p )                  # ttest on ranks power
  #  cat("\nMean intercept\n")
  # print(mean( unlist(x[,"V6"])) )  # intercept
  # cat("Mean treatment effect\n")
  # print(mean( unlist(x[,"V7"]))  )  # beta
  # cat("Mean SD of differences\n")
  # print(mean( unlist(x[,"V8"])) )  # sd of diff
  
 # cat("Theoretical SD of differences\n")
  R <- input$r# seq(-.9,.9,.1)   # correlation
  X <- input$mu0.p               # var of poisson (= mean)
  Y <- input$mu0.p*input$eff.p              # var of poisson (= mean)
  #print(cbind(R,   sqrt(X+Y-(2*sqrt(X)*sqrt(Y)*R))))
 

  
  cat(paste0("Evaluations based on ",input$sims.p," simulations take into consideration correlation, the default starting value is "
             ,input$r,"\nThe median p-value from a mixed effects Poisson model is "
             ,median( unlist(x[,"V2"]))   , 
             ". \nPower based on the mixed model Wald test is ",
             #,input$eff.p,
             #"\nEvaluations are based on a stated correlation, starting value "
             #,input$r,
             
      (table( unlist(x[,"V2"])< alpha)/input$sims.p)[2][[1]],
      
      "\nPower based on the Wilcoxon signed rank test power is ",
      (table( unlist(x[,"V3"])< alpha)/input$sims.p)[2][[1]],
      "\nMean Hodeges Lehman estimator is ",
        mean( unlist(x[,"V9"]))," with 95%CI ",quantile(unlist(x[,"V9"]), .025)," to ",quantile(unlist(x[,"V9"]), .975),
      "\nPower based on the t-test is ",
      (table( unlist(x[,"V4"])< alpha)/input$sims.p)[2][[1]],
      "\nPower based on the t-test of ranks is ",
      (table( unlist(x[,"V5"])< alpha)/input$sims.p)[2][[1]],
    " \nThe mean intercept is ",
          mean( unlist(x[,"V6"])),
       "\nThe mean treatement effect is ",
          mean( unlist(x[,"V7"]))," with 95%CI ",quantile(unlist(x[,"V7"]), .025)," to ",quantile(unlist(x[,"V7"]), .975),
      "\nMean SD of differences is ", 
     mean( unlist(x[,"V8"])),  
    
     "\nThe theoretical SD of differences based on Poisson variances and stated correlation is ",
    sqrt(X+Y-(2*sqrt(X)*sqrt(Y)*R)),
    "\n"))
  
   
  
 # c(rate.reduction,mix , wil,t.t,  ttor,intercept, beta ,sdd)

})

```

   
Row {.tabset .tabset-fade}
-----------------------------------------------------------------------

### Typical expected dataset (jitter added to counts)
  

```{r, eval=TRUE}

#https://stackoverflow.com/questions/52225348/shiny-flexdashboard-reference-object-in-new-tabset#52225733

   dat2 <- reactive(
    
      

   # 
GenerateMultivariatePoisson(p=2, samples=input$N.p, R=matrix(c(1, input$r, 
                                                                     input$r, 1), 2, 2), lambda=c(input$mu0.p, input$mu0.p*input$eff.p))
     
     
  )



 renderPlot({   
   
 dat2 <- dat2()

   
   dx <- dat2
   
   
library(ggplot2)
A <- dx[,1]
B <- dx[,2]
before <- A + runif(length(dx[,1]),-.2,.2)
after <-  B + runif(length(dx[,2]),-.2,.2)
n <- length(before)
d <- data.frame(y = c(before, after), 
                x = rep(c(1,2), each=n),
                id = factor(rep(1:n,2)))

#set.seed(321)    
d$xj <- jitter(d$x, amount=.03)
AA <- ggplot(data=d, aes(y=y) ) +
  geom_boxplot(aes(x=x, group=x), width=0.2, outlier.shape = NA) +
  geom_line(aes(x=xj, group=id),  colour='pink', alpha=.5) +
  geom_point(aes(x=xj)) +
  xlab("Phase") + ylab("Count") + #title("Typical expected dataset") +
  scale_x_continuous(breaks=c(1,2), labels=c("Before", "After"), limits=c(0.5, 2.5)) +
  theme_bw() + theme(legend.position = "none")# +
 #   ggtitle("Typical expected dataset") 
#~~~~~~~~~~~~~~~~~~~~~

 d <- data.frame(y = B ,
                x = A)

set.seed(1) 

m <- max(A,B)

BB <- ggplot(d, aes(x, y)) +
  geom_jitter(width = 0.1, height = 0.1) +
 scale_x_continuous(breaks=c(0:m), limits=c(0,m)) +
 scale_y_continuous(breaks=c(0:m), limits=c(0,m)) +
  xlab("Before count") +ylab("After count") +
 #xlim (0, m) + ylim(0, m) +
  theme_bw() + theme(legend.position = "none")#



require(gridExtra)
plot1 <- AA
plot2 <- BB
grid.arrange(plot1, plot2, ncol=2)


})


```

 
<<<<<<< HEAD
### Typical expected dataset - Bland Altman plot, square root transformation
=======
### Typical expected dataset - Bland Altman plot
>>>>>>> c2cf3989cf113b233c8710d7ad0e965d326533fc

```{r}


 renderPlot({
   
    d <- dat2()

#BAplot
require(MethComp)

my_data <- data.frame( 
  group = rep(c("before", "after"), each = input$N.p),
  counts = c(d[,1],  d[,2]),
  ID=rep(1:input$N.p,2)
)

m <- Meth(my_data,meth="group",item="ID",repl=NULL,y="counts",print=TRUE)

BA.plot( m, model=NULL, repl.conn=TRUE, col.lines="blue",
         axlim=c(0,20), diflim=c(-20,20), xaxs="i", yaxs="i",
         las=1, eqn=FALSE, dif.type="lin", pl.type="BA", sd.type="lin",
         grid=1:9*10, digits=3,font.eqn=1 , Transform='sqrt') 


})




```


References
====

```
https://stackoverflow.com/questions/52225348/shiny-flexdashboard-reference-object-in-new-tabset#52225733
