---
title: "Illustrating negative binomial distributions"
author: 
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    social: menu
    source_code: embed
runtime: shiny
---
Probability Mass Functions
===

```{r global, include=FALSE}

  library(MASS)  # for neg binomial analysis and correlated data generation
  library(ggplot2)
  library(lme4)
  library(shiny)
  library(utf8)  # codes for Greek letters
  library(MethComp)
  library(gridExtra)
  lwd.=3

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# another dnbinom Function   
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 my_dnbinom=function(x,mu,alpha){
  m = mu
  k = 1/alpha
  # lgamma is log(gamma)
  a = lgamma(k+x)-lgamma(k)-lgamma(x+1)
  b = x*log(m/(m+k))
  c = -k*log(1+m/k)
  prob = exp(a+b+c)
  prob[x<0] = 0
  prob[prob>1] = 1
  prob[prob<0] = 0
  return(prob)
}

# check
# dnbinom(   1, size=2,   mu=3)
# my_dnbinom(1, alpha=1/2,mu=3)

##################################################################################
# R has built-in random number generators for the binomial distribution,
# but they are expressed in different form than the form in the Lloyd-Smith
# PLoS paper. This function translates the mu and alpha parameters
# into the format needed by R to generate the NB random numbers
##################################################################################
my_rnbinom=function(n,mu,alpha){
  size = 1/alpha          # so now we can just enter alpha this is converted to 1/ alpha
  prob = size/(mu+size)   # so now we can enter mu the mean and that is converted to prob
  return(rnbinom(n,size=size,prob=prob))
}

 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # generate cor data function
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

GenerateMultivariatePoisson<-function(p, samples, R, lambda){
  normal_mu=rep(0, p)
  normal = mvrnorm(samples, normal_mu, R)
  unif=pnorm(normal)
  pois=t(qpois(t(unif), lambda))
  return(pois)
}
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # another function to generate cor data 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  mvrnorm <- function(n = 1, mu = 0, Sigma) {
    nvars <- nrow(Sigma)
    # nvars x n matrix of Normal(0, 1)
    nmls <- matrix(rnorm(n * nvars), nrow = nvars)
    # scale and correlate Normal(0, 1), "nmls", to Normal(0, Sigma) by matrix mult
    # with lower triangular of cholesky decomp of covariance matrix
    scaled_correlated_nmls <- t(chol(Sigma)) %*% nmls
    # shift to center around mus to get goal: Normal(mu, Sigma)
    samples <- mu + scaled_correlated_nmls
    # transpose so each variable is a column, not
    # a row, to match what MASS::mvrnorm() returns
    t(samples)
  }
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# function to simulate negative binomial RCT
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  
nb.power <- function(n=220, k=1.3, mu0=1, eff=0.65, drop1=.1, drop2=.1, fup=1) {
  
  mu1 <- eff*mu0
  
  # n=220; alpha=1.3; mu0=1; mu1=.65; drop1=.01; drop2=.01; fup=1
  # just so there is no error if dropo out is zero
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  
 
  dose <- c(rep("placebo",n),rep("trt",n)) # 50:50 split of patients
  
  mu   <- c(rep(mu0,n), rep(mu1,n))        # rates in two arms

  drop <- c(rep(drop1,n), rep(drop2,n)) # }# tr discontinuation rates
  
  f    <- - rexp(2*n) / log(1-drop)
  
  length <- ifelse(f > fup, fup, f)        # curtail at follow up time 
  
  y  <-  rnbinom(n*2,  prob=1/(1+ mu*length* k),        size=1/k)  +   # on treatment events
         rnbinom(n*2,  prob=1/(1+ mu0*(fup-length)*k),  size=1/k)      # accounting for any off treat. 
  
  # assume no is lost to the study but can discontinue treatment
  lfup     <- log(fup)         # exposure log(fup) for everyone, that is fup year
  logleng  <- rep(lfup, n*2)   #  
  
  # analyse with neg. binomial model
  x <- summary(MASS::glm.nb(y~dose+offset((logleng))))
 
  # collect p-values
  p <-  x$coefficients["dosetrt","Pr(>|z|)"]
  
  return(p)
  
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# function to generate correlated poisson and analyse and evaluate
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 
po.cor.power <- function(n=22, r=.75, mu0=10, eff.p=.75) { # r correlation mu0 placebo rate, mu1 expected change in rate
   
  #n=22; r=.75; mu0=10; eff.p=.75
  # 1. create correlated poisson
  # 2. analyse many times and examine

  L1 <- mu0
  L2 <- mu0*eff.p
  
  # generate correlated poisson ref: https://thomasward.com/simulating-correlated-data/
  
  # Sample correlated N(0, 1) distributions from a multivariate normal distribution.
  # Transform them to correlated Uniform(0, 1) distributions with the normal CDF.
  # Transform them to any correlated probability distribution you desire with that probability distribution’s inverse CDF.
  
  Sigma <- matrix(c(1, r, r, 1), 2, 2)
  #Sigma
  

  p2 <- mvrnorm(n, Sigma = Sigma)   # correlated continuous  # see function in global area!
  
  U <- pnorm(p2, mean = 0, sd = 1)  # correlated uniform
  
  pp1 <- qpois(U[, 1], L1)          # correlated poisson
  pp2 <- qpois(U[, 2], L2)          # correlated poisson
  
  cor. <- cor(pp1,pp2)
  
  # create a data frame
  my_data <- data.frame( 
    group = rep(c("A.before", "B.after"), each = n),
    counts = c(pp1,  pp2),
    ID=rep(1:n,2)
  )
  

   
  A <- glmer(counts ~ group + (1|ID), data=my_data, family="poisson")
 # B <- glmer(counts ~ 1     + (1|ID), data=my_data, family="poisson")  # dont use LRT to speed up sims
 # p <- anova(A,B)
 # mix <-  p$`Pr(>Chisq)`[2]
  
  x <- summary(A)
  mix <- summary(A)$coeff[2,"Pr(>|z|)"]  # to speed up simulations dont use LRTtest but wald
  
  rate.reduction <- exp(x$coefficients[2,1])
  
  intercept <- exp( x$coefficients[1,1])
  beta      <- exp( x$coefficients[2,1])
  
  x1 <- pp2 - pp1                                     # post - pre
  
  w <- wilcox.test(x=x1, paired=FALSE, correct=FALSE, conf.int=TRUE  ,conf.level = 0.95)
   
  wil <- w$p.value
  wile <- w$estimate[1][[1]]
  
  t.t <- t.test(x=x1, paired=FALSE)$p.value # t.test(x1)$p.value 
   
  signed_rank = function(x) sign(x) * rank(abs(x))
  ttor <- t.test(signed_rank(x1))$p.value
  
  # wilcox.test(x1)
  # t.test(signed_rank(x1))
  
  #lets capture SD of differences
  sdd <- sd(x1)
  
  #newList <- list("glmer" = mix , "Wilcoxon signed rank test" = wil,
              #    "t.test"=t.t, "rate reduction"= rate.reduction, "intercept"=intercept, "beta"=beta,
               #   "ttest on ranks"=ttor, "sd of diff"=sdd)
  #return(newList)
  
  
  
  c(rate.reduction,mix , wil,t.t,  ttor,intercept, beta ,sdd, wile, cor.)
  
}


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# start of app
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```


Column {.sidebar}
-----------------------------------------------------------------------

Count data analysis is explored...

```{r}


  sliderInput('mu', 'Common  \u03BC', value=1.5,
                min = 1, max = 25, step=.5, ticks=F)
  
  sliderInput('alpha_a', '\u03B1 for red curve', value = c(0.8),
                min = 0, max = 5 ,step=0.01, ticks=F)
  
  sliderInput('alpha_b', '\u03B1 for dark blue curve', value = c(0.8),
                min = 0, max = 5 ,step=0.01, ticks=F)
  
  sliderInput('alpha_d', '\u03B1 for purple curve', value = c(0.8),
                min = 0, max = 5 ,step=0.01, ticks=F)
  
  sliderInput('sims', 'Simulations (chart 2)', 50000,
                min = 50000, max = 500000,step=50000,ticks=F)
  
  sliderInput('x_range', 'Plot x-range', value = c(0,10),
          min = 0, max = 80,step=5,ticks=F)
  
  sliderInput('y_range', 'Plot y-range', value = c(0,.4),
          min = 0, max = 1,step=.05,ticks=F)

 

```

This page of the app uses  $\alpha$. 

$\alpha$ takes on positive rational values, rarely above 4 (Hilbe page 190)

When  $\alpha$ approaches 0, k is infinite and Poisson emerges (move red $\alpha$ slider to 0).

When  $\alpha$ > 1, k < 1 highly leads to over dispersed data ($\alpha$ big).

$\alpha$ = 1/k

k = 1/ $\alpha$
 

Column {data-width=400, height=300}
-----------------------------------------------------------------------
### Chart 1


```{r}

renderPlot({
  
##################################################################################
# Define the Negative Binomial probability density function, with parameters
# mu and alpha. The mean of this NB distribution is mu, and variance is sigma^2=mu+alpha*mu^2
##################################################################################

##################################################################################
# Now let's try out the NB density function, and overlay the Poisson
# distribution with the same mean
##################################################################################
 
  # mu = sample(1:25,1)
  # alpha_a = 0.1
  # alpha_b = .01
  # alpha_d = 1

  mu = input$mu
  alpha_a = input$alpha_a
  alpha_b =  input$alpha_b
  alpha_d =  input$alpha_d
  low =  input$x_range[1]
  high=  input$x_range[2]
  xmax = high
  ymax = input$y_range[2]

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  # if else turn neg binomial into poisson if alpha =0
  x=c(-0.0001,seq(0,xmax,1))
  
  y =          dpois(x,mu)
   
  if(alpha_a==0) {
  yb =          dpois(x,mu)
  }else{
  yb=     my_dnbinom(x,mu,alpha_a)
  }
  
  if(alpha_b==0){
  yc =          dpois(x,mu)
  }else{
  yc=     my_dnbinom(x,mu,alpha_b)
  }
  
  if(alpha_d==0){
  yd =          dpois(x,mu)
  }else{
  yd=     my_dnbinom(x,mu,alpha_d)
  }
  
  nor <-       dnorm(x, mu, sqrt(mu))


  x=  append(0,x)  
  y=  append(0,y)
  yb= append(0,yb)
  yc= append(0,yc)
  yd= append(0,yd)
  nor=append(0,nor)
  
  l = !is.na(y+yb+yc+yd+nor)
  
  plot(x[l],y[l],ylim=c(0,ymax),xlim=c(low,xmax),type="l",lwd=lwd.,xlab="x",
       ylab="prob(x)",main="Probability distributions")
  
  lines(x[l],yb[l], col=2,lwd=lwd.,type="l")
  lines(x[l],yc[l], col=4,lwd=lwd.,type="l")
  lines(x[l],nor[l],col=5,lwd=lwd.,type="l")
  lines(x[l],yd[l], col=6,lwd=lwd.,type="l")
   
 
  apois = paste("Poisson \u03BC=",mu,sep="")
  anegbinom_a = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_a,sep="")
  anegbinom_b = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_b,sep="")
  anegbinom_c = paste("Normal \u03BC=",   mu," \u03C3=sqrt(",mu,")",sep="")
  anegbinom_d = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_d,sep="")
  
  
  legend("topright",col=c(1,2,4,6,5),legend=c(apois,anegbinom_a,anegbinom_b, anegbinom_d, anegbinom_c),
         lwd=lwd.,bty="n")
 }
)




```


### Chart 2

```{r}

renderPlot({
  

    n=input$sims
    
    mu = input$mu
    alpha_a =  input$alpha_a
    alpha_b =  input$alpha_b
    alpha_d =  input$alpha_d
    low =      input$x_range[1]
    xmax=      input$x_range[2]
    ymax =     input$y_range[2]
    
    z  =      rpois(n,mu)
    zb = my_rnbinom(n,mu,alpha_a)
    zc = my_rnbinom(n,mu,alpha_b)
    zd =      rnorm(n,mu,sqrt(mu))
    ze = my_rnbinom(n,mu,alpha_d)
    
    a=hist(z, plot=F,breaks=seq(-1.5,n+.5,1))
    b=hist(zb,plot=F,breaks=seq(-1.5,n+.5,1))
    c=hist(zc,plot=F,breaks=seq(-1.5,n+.5,1))
    d=hist(zd,plot=F,breaks=200)
    e=hist(ze,plot=F,breaks=seq(-1.5,n+.5,1))
    
    atitle = paste("Distributions of",n,"random numbers")
    
    plot(a$mids,a$density,type="s",lwd=lwd.,col=1,ylim=c(0,ymax),main=atitle,xlim=c(low,xmax),
         xlab="x",ylab="Fraction falling within each bin")
    
    lines(b$mids,b$density,type="s",lwd=lwd.,col=2)
    lines(c$mids,c$density,type="s",lwd=lwd.,col=4)
    lines(d$mids,d$density,type="s",lwd=lwd.,col=5)
    lines(e$mids,e$density,type="s",lwd=lwd.,col=6)
    
    apois =       paste("Poisson \u03BC="  ,mu,  sep="")
    anegbinom_a = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_a,     sep="")
    anegbinom_b = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_b,     sep="")
    anegbinom_c = paste("Normal \u03BC=",   mu," \u03C3=sqrt(",mu,")", sep="")
    anegbinom_d = paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_d,     sep="")
    
    legend("topright",col=c(1,2,4,6,5),legend=c(apois,anegbinom_a,anegbinom_b, anegbinom_d, anegbinom_c),
           lwd=lwd.,bty="n")


})


 
```

Column {data-width=400}
-------------------------------------

### Chart 3

```{r}


renderPlot({
  
  mu = input$mu
  alpha_a = input$alpha_a
  low =  input$x_range[1]
  xmax=  input$x_range[2]
  ymax = input$y_range[2]
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 
  xx <- c(seq(0,xmax,1))

  yb = dpois(xx,mu)
  
  par(mar=c(2.1,4.1,4.1,4.1))
      
  barplot(yb, xlim=c(0,xmax+2), ylab = "Percent", xlab="x", col='black', ylim=c(0,ymax),
          main = paste("Poisson \u03BC=", mu, ", based on common \u03BC",sep=""),
          names.arg= as.character(xx))
})

```

### Chart 4

```{r}

 
    renderPlot({
  
    mu = input$mu
    alpha_a = input$alpha_a
  
  
    low =  input$x_range[1]
    xmax=  input$x_range[2]
    ymax = input$y_range[2]

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  xx <- c(seq(0,xmax,1))

  if(alpha_a==0) {
  yb =          dpois(xx,mu)
  }else{
  yb=     my_dnbinom(xx,mu,alpha_a)
  }
  
  par(mar=c(2.1,4.1,4.1,4.1))
      
  barplot(yb, xlim=c(0,xmax+2), ylab = "Percent", xlab="x", col='red',
          ylim=c(0,ymax),
          main =  paste("Negative Binomial \u03BC=",mu," \u03B1=",alpha_a,", based on common mean and red curve \u03B1",sep=""),
          names.arg= as.character(xx))
  
})
    
    
   


```
 

Negative binomial power
====

Column {.sidebar}
-----------------------------------------------------------------------

Use the inputs below to simulate an RCT with a count outcome measure. We estimate the treatment effect using a negative binomial model   

```{r}
 

    sliderInput('N', 'Patients per arm', value=220,
                  min = 10, max = 10000, step=5, ticks=F)
    
    sliderInput('mu0', 'Placebo mean rate \u03BC', value=1,
                  min = 0.1, max = 25, step=.05, ticks=F)
    
    sliderInput('eff', 'Hypothesised treatment effect ', value=.75,
                  min = 0.1, max = 25, step=.05, ticks=F)
    
    sliderInput('k', '1/\u03B1 the heterogeneity (ancillary) parameter', value = c(1.3),
                  min = 0, max = 5 ,step=0.01, ticks=F)
    
    sliderInput('d1', 'Placebo discontinuation prob', value = c(0.1),
                  min = 0, max = .5 ,step=0.05, ticks=F)
    
    sliderInput('d2', 'Treatment discontinuation prob', value = c(0.1),
                  min = 0, max = .5 ,step=0.05, ticks=F)
    
    sliderInput('fup', 'Follow up (yrs)', value = c(1),
            min = 0, max = 10, step=1,ticks=F)
     
    sliderInput('sims2', 'Power simulations', value= 500,
                  min = 500, max = 10000, step= 500, ticks=F)
 
 

```

Row {data- height=650}
-----------------------------------------------------------------------
### Power will appear here iminently...be patient...
  
```{r, eval=TRUE}

reactive({
  
cat(paste0("A RCT with 1:1 randomisation is being planned to investigate an intervention on the rate of asthma exacerbations with ",input$N," patients per arm.\n"))

cat(paste0("The negative binomial model will be used as we expect patient heterogeneity of exacerbations beyond that captured by patient level covariates.\nWe will use the natural log of duration of follow up time as an offset variable, the duration of follow up ",input$fup, " will be the planned duration of follow up for all patients."))

cat(paste0("\nk is the dispersion parameter, its value is " ,input$k,", this is the same as 1/alpha So alpha is ",1/input$k,". The rate for placebo is ",input$mu0," events per patient year of follow up.\nThe treatment effect hypothesised is ",input$eff, ". \nDrop out probabilities for treatment discontinuation and follow up period (in years) are " ,input$d1, " and " ,input$d2," respectively. \nWe assume a constant exponential hazard rate over time for treatment discontinuation with ",input$d1," and ",input$d2,", the percentages of patients\noff treatment by follow up time in years in active and placebo. \nNo further treatment effect versus placebo is assumed during off treatment, that is ",input$mu0," events per patient year is assumed for patients after treatment discontinuation in treated and placebo.\n"))

cat(paste0("\nThe power estimate is..."))
})
  
 
reactive({
  
  res <- replicate( input$sims2, 
        nb.power(n=input$N, k=input$k, mu0=input$mu0, eff=input$eff, drop1=input$d1, drop2=input$d2, fup=input$fup)) 
  mean(res<0.05)

})


```
 
Row {data-height=350}
-------------------------------------
   
### A typical dataset that can be expected

```{r}

 renderPlot({
  
   n=     input$N
   k=     input$k
   mu0=   input$mu0
   eff=   input$eff
   drop1= input$d1
   drop2= input$d2
   fup=   input$fup
   
   mu1 <- eff*mu0
   
  dose <- c(rep("placebo",n),rep("trt",n))
  mu   <- c(rep(mu0,n),rep(mu1,n))
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  drop <- c(rep(.1,n),rep(.1,n))

  f <- - rexp(2*n) / log(1-drop)
  length <- ifelse(f>1,1,f)
 
  y <-  rnbinom(n*2,  p=1/(1+ mu*length* k),      size=1/k)  +
        rnbinom(n*2,  p=1/(1+ mu0*(1-length)*k),  size=1/k)

  logleng  <- rep(0, n*2)

  #addmargins(table( y,  dose))

 # d <- cbind.data.frame(dose, mu, length, y, logleng)
 # summary(MASS::glm.nb(y~dose+offset((logleng)), data=d))

  trt <- y[dose %in% "trt"]
  pla <- y[!dose %in% "trt"]
  
# examine
# par(mfrow=c(1,2))
# trt %>% table %>% barplot() #quick and dirty
# trt %>% table %>% prop.table
# pla %>% table %>% barplot() #quick and dirty
# pla %>% table %>% prop.table
# par(mfrow=c(1,1))
  
  upp <- ceiling(max(prop.table(table(y))) * 100 ) 
  par(mfrow=c(1,2))
  data_perc <- t(prop.table(table(trt))) * 100    # Convert data to probability table
  barplot(data_perc, ylab = "Percent", main ="Treated", ylim=c(0,upp ))     
  data_perc <- t(prop.table(table(pla))) * 100    # Convert data to probability table
  barplot(data_perc, ylab = "Percent", main ="Placebo", ylim=c(0,upp ))     
  par(mfrow=c(1,1))

})



```   
 
   
### A typical result that can be expected, theta is synonymous with $\alpha$

```{r}

 renderPrint({
  
 n=input$N
 k=input$k
 mu0=input$mu0
 eff=input$eff
 drop1=input$d1
 drop2=input$d2
 fup=input$fup
 
 mu1 <- eff*mu0
 
  dose <- c(rep("placebo",n),rep("trt",n))
  mu   <- c(rep(mu0,n),rep(mu1,n))
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  drop <- c(rep(.1,n),rep(.1,n))

  f <- - rexp(2*n) / log(1-drop)
  length <- ifelse(f>1,1,f)
 
  y <-  rnbinom(n*2,  p=1/(1+ mu*length* k),      size=1/k)  +
        rnbinom(n*2,  p=1/(1+ mu0*(1-length)*k),  size=1/k)

  logleng  <- rep(0, n*2)

  #addmargins(table( y,  dose))

  d <- cbind.data.frame(dose, mu, length, y, logleng)
  print (f <- summary(MASS::glm.nb(y~dose+offset((logleng)), data=d)))
  
cat(paste0("\nPlacebo rate ",round(exp(f$coef[1]),4)," and multiplicative treatement effect of ",round(exp(f$coef[2]),4),""))
    
})
  
``` 

Poisson paired counts
====

Column {.sidebar}
-----------------------------------------------------------------------


Use the inputs below to generate correlated count data !

```{r}


  sliderInput('N.p', 'Patients per arm', value=22,
                min = 10, max = 200, step=5, ticks=F)
  
  sliderInput('mu0.p', 'Placebo mean rate \u03BC', value=10,
                min = 0.1, max = 25, step=.05, ticks=F)
  
  sliderInput('eff.p', 'Hypothesised treatment effect ', value=.75,  # 1/2 ing to doubling
                min = 0.5, max = 2, step=.05, ticks=F)
  
  sliderInput('r', 'Correlation', value = c(.20),
                min = -1, max = 1 ,step=0.05, ticks=F)
   
  sliderInput('sims.p', 'Power simulations', value= 10,
                min = 100, max = 1000, step= 100, ticks=F)
 

```

Row {data-height=275}
-----------------------------------------------------------------------

### Single arm pre post study design simulation
  

```{r, eval=TRUE}

 
reactive({
  
cat(paste0("This is an example of paired study design in which the outcome measure is counts of events and which does not use a concurrent control, so is not a great study design. \nNevertheless, we have ",input$N.p," subjects assessed before and after an intervention. The Poisson model will be used, the observation time is the same for the the pre and post periods.\n"))

cat(paste0("We will simulate the data based on a expected rate before the intervention of ",input$mu0.p, " and an hypothesised effect of intervention ",input$eff.p,", so a hypothesised mean rate of ",input$mu0.p*input$eff.p," for the intervention.\nWe also take into account the correlation between obervations for the same individual, the starting value is " ,input$r,".\n")) 

cat(paste0("\nWe report the average p-value from a mixed Poisson model and the power, Wilcoxon signed rank test power, T test power, T test on ranks power, intercept, treatment effect and SD of differences. \nWe also quote the theoretical SD of differences."))

cat(paste0("\nTo generate correlated Poisson variables we..."))
cat(paste0("\n1) Sample two correlated N(0, 1) distributions from a multivariate normal distribution."))
cat(paste0("\n2) Transform them to correlated Uniform(0, 1) distributions using the normal CDF."))
cat(paste0("\n3) Transform them to the desired correlated probability distribution desired using that probability distribution’s inverse CDF!"))
 
})


``` 

Row {data-height=250}
-----------------------------------------------------------------------

### Results


```{r, eval=TRUE}

reactive({
  
  res <- replicate(input$sims.p, 
                   po.cor.power(n=input$N.p, r=input$r, mu0=input$mu0.p,  eff.p=input$eff.p ) )  

  x <- NULL
  x <- t((res))
  x <- as.data.frame(x)
  alpha=0.05
 
  
  # cat("Theoretical SD of differences\n")
  R <- input$r# seq(-.9,.9,.1)   # correlation
  X <- input$mu0.p               # var of poisson (= mean)
  Y <- input$mu0.p*input$eff.p   # var of poisson (= mean)


  
  cat(paste0("Evaluations based on ",input$sims.p," simulations take into consideration correlation, the default starting value is "
       ,input$r,". The observed mean correlation is ",mean( unlist(x[,"V10"])), "\nThe median p-value from a mixed effects Poisson model is "
       ,median( unlist(x[,"V2"]))   , 
       ". \nPower based on the mixed model Wald test is ",
             
      (table( unlist(x[,"V2"])< alpha)/input$sims.p)[2][[1]],
      
      "\nPower based on the Wilcoxon signed rank test power is ",
      (table( unlist(x[,"V3"])< alpha)/input$sims.p)[2][[1]],
      "\nMean Hodeges Lehman estimator is ",
        mean( unlist(x[,"V9"]))," with 95%CI ",quantile(unlist(x[,"V9"]), .025)," to ",quantile(unlist(x[,"V9"]), .975),
      "\nPower based on the t-test is ",
      (table( unlist(x[,"V4"])< alpha)/input$sims.p)[2][[1]],
      "\nPower based on the t-test of ranks is ",
      (table( unlist(x[,"V5"])< alpha)/input$sims.p)[2][[1]],
      " \nThe mean intercept is ",
      mean( unlist(x[,"V6"])),
      "\nThe mean treatement effect is ",
      mean( unlist(x[,"V7"]))," with 95%CI ",quantile(unlist(x[,"V7"]), .025)," to ",quantile(unlist(x[,"V7"]), .975),
      "\nMean SD of differences is ", 
      mean( unlist(x[,"V8"])),  
    
      "\nThe theoretical SD of differences based on Poisson variances and stated correlation is ",
      sqrt(X+Y-(2*sqrt(X)*sqrt(Y)*R)),
      "\n"))
   

})

```

   
Row {.tabset .tabset-fade}
-----------------------------------------------------------------------

### Typical expected dataset (jitter added to counts)
  

```{r, eval=TRUE}


   dat2 <- reactive(
 
    GenerateMultivariatePoisson(p=2, samples=input$N.p, R=matrix(c(1, input$r, 
                                                                     input$r, 1), 2, 2), 
                                lambda=c(input$mu0.p, input$mu0.p*input$eff.p))
    )



 renderPlot({   
   
  dat2 <- dat2()

  dx <- dat2

  # boxplot
  A <- dx[,1]
  B <- dx[,2]
  m <- max(A,B)
  before <- A + runif(length(dx[,1]),-.2,.2)
  after <-  B + runif(length(dx[,2]),-.2,.2)
  n <- length(before)
  d <- data.frame(y = c(before, after), 
                  x = rep(c(1,2), each=n),
                  id = factor(rep(1:n,2)))

  
  d$xj <- jitter(d$x, amount=.03)
  AA <- ggplot(data=d, aes(y=y) ) +
    geom_boxplot(aes(x=x, group=x), width=0.2, outlier.shape = NA) +
    geom_line(aes(x=xj, group=id),  colour='pink', alpha=.5) +
    geom_point(aes(x=xj), size=2) +
    xlab("Phase") + ylab("Count") +  
    scale_x_continuous(breaks=c(1,2), labels=c("Before", "After"), limits=c(0.5, 2.5)) +
     scale_y_continuous(breaks=c(0:m), limits=c(0,m)) +
    theme_bw() + theme(legend.position = "none") 
    
#~~~~~~~~~~~~~~~~~~~~~
  
     # scatterplot

     d <- data.frame(y = B ,
                     x = A)

#    
      BB <- ggplot(d, aes(x, y)) +
      geom_jitter(width = 0.1, height = 0.1, size=2) +
      scale_x_continuous(breaks=c(0:m), limits=c(0,m)) +
      scale_y_continuous(breaks=c(0:m), limits=c(0,m)) +
      xlab("Before count") +ylab("After count") +
      theme_bw() + theme(legend.position = "none") +
        geom_abline(intercept=0, slope=1)

      plot1 <- AA
      plot2 <- BB
      grid.arrange(plot1, plot2, ncol=2)


})


```


### Typical expected dataset - Bland Altman plot, square root transformation
 
 
```{r}


 renderPlot({
   
    d <- dat2()

    my_data <- data.frame( 
      group = rep(c("before", "after"), each = input$N.p),
      counts = c(d[,1],  d[,2]),
      ID=rep(1:input$N.p,2)
    )

    m <- Meth(my_data,meth="group",item="ID",repl=NULL,y="counts",print=TRUE)
    
    BA.plot( m, model=NULL, repl.conn=TRUE, col.lines="blue",
             axlim=c(0,20), diflim=c(-20,20), xaxs="i", yaxs="i",
             las=1, eqn=FALSE, dif.type="lin", pl.type="BA", sd.type="lin",
             grid=1:9*10, digits=3,font.eqn=1 , Transform='sqrt') 

})

 
``` 

Poisson gamma!
====

Column {.sidebar}
-----------------------------------------------------------------------

Show the equivalent parameterisation of Poisson gamma and negative binomial !

```{r}


  sliderInput('N.pg', 'Patients per arm', value=1000,
                min = 100, max = 100000, step=5, ticks=F)
  
  sliderInput('mu0.pg', 'Placebo mean rate \u03BC', value=1,
                min = 0.1, max = 25, step=.05, ticks=F)
  
  sliderInput('eff.pg', 'Hypothesised treatment effect ', value=.75,  # 1/2 ing to doubling
                min = 0.5, max = 2, step=.05, ticks=F)
  
    sliderInput('k.pg', '1/\u03B1 the heterogeneity (ancillary) parameter', value = c(1.3),
                  min = 0, max = 5 ,step=0.01, ticks=F)
    
    sliderInput('d1.pg', 'Placebo discontinuation prob', value = c(0.1),
                  min = 0, max = .5 ,step=0.05, ticks=F)
    
    sliderInput('d2.pg', 'Treatment discontinuation prob', value = c(0.1),
                  min = 0, max = .5 ,step=0.05, ticks=F)
  
    sliderInput('fup.pg', 'Follow up (yrs)', value = c(1),
            min = 0, max = 10, step=1,ticks=F)
    #  
    # sliderInput('sims.pg', 'Power simulations', value= 10,
    #             min = 100, max = 1000, step= 100, ticks=F)
    # 
# n  <- 1000
# k  <- 1.3   # this is k, alpha=1/k
# 1/k         # alpha reported as theta in neg binomial
# mu0 <- 1
# mu1 <- mu0*0.75
# 
# fup   <- 1
# drop1 <- 0.1
# drop2 <- 0.1
  
  
  
```

Column {data-width=400, height=300}
-----------------------------------------------------------------------

### Poisson gamma data simulation

```{r, eval=TRUE}


dat3 <- reactive({
 

k <-   input$k.pg
n <-   input$N.pg 
mu0 <- input$mu0.pg
mu1 <- mu0*input$eff.pg
d1 <-  input$d1.pg
d2 <-  input$d2.pg

s <-  rgamma(n, shape = 1/k, scale = k)
s1 <- rgamma(n, shape = 1/k, scale = k)
 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dose <- c(rep("placebo",n),rep("trt",n))
mu   <- c(rep(mu0,n),rep(mu1,n))
drop <- c(rep(d1,n),rep(d2,n))
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# discontinuations and follow up
f        <- - rexp(2*n) / log(1-drop)
length   <- ifelse(f>1,1,f)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

lambda1 <- mu   * s  ## Simulate rate
lambda2 <- mu0 * s1  ## Simulate rate

y_0 <- rpois(n = n*2, lambda = (length*lambda1))  +
       rpois(n = n*2, lambda = ((1-length)*lambda2))  
 
       logleng  <- rep(0, n*2)  # all patients have same length follow up

f1<-glm.nb(y_0~dose+offset(logleng) )

})


renderPrint({
 
     dat3 <- dat3()
     summary(dat3)
    })

``` 


### Negative binomial data simulation


```{r, eval=TRUE}


dat4 <- reactive({

k <-    input$k.pg
n <-    input$N.pg 
mu0 <-  input$mu0.pg
mu1 <-  mu0*input$eff.pg
d1 <-   input$d1.pg
d2 <-   input$d2.pg

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dose <- c(rep("placebo",n),rep("trt",n))
mu   <- c(rep(mu0,n),rep(mu1,n))
drop <- c(rep(d1,n),rep(d2,n))
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# discontinuations and follow up
f        <- - rexp(2*n) / log(1-drop)
length   <- ifelse(f>1,1,f)

y <-  rnbinom(n*2,  p=1/(1+ mu*    length* k),  size=1/k)  +
      rnbinom(n*2,  p=1/(1+ mu0*(1-length)*k),  size=1/k)

logleng  <- rep(0, n*2)
 
f<-glm.nb(y~dose+offset(logleng) )

})
 

renderPrint({
 
     dat4 <- dat4()
     summary(dat4)
    })



```
   
Column {.tabset .tabset-fade}
-----------------------------------------------------------------------

### Plot1
  

```{r, eval=TRUE}


 renderPlot({
   
 f1 <- dat3()
 f <- dat4()
   
 par(mfrow=c(1,2))
 countreg::rootogram(f1, style = "hanging",     main = "Hanging plot gamma poisson")
 countreg::rootogram(f,  style = "hanging",     main = "Hanging plot rnbinomial")
 par(mfrow=c(1,1))
 
 })

```

### Plot2
 
 
```{r}


library(vcd)

 renderPlot({
   
 f1 <- dat3()
 f <- dat4()

 #par(mfrow=c(1,2))
# Ord_plot(f1$y)
 distplot(f1$y, type="poisson")
 distplot(f1$y, type="nbinom")
 #par(mfrow=c(1,1))

 })



```
 

### Plot3
  

```{r, eval=TRUE}

```

### Plot4
 
 
```{r}






```

Notes
===
gelmans book rnegbiniom function
gamma and rnbinom equivalence
investigate offset 
predict
friendly's book and code
hilbe code with discontinuationand s  
cor neg binomial not working
explain corr poisson approach <- many packages
understand neg binomial rct rnbinom inputs
gamma - see basics plot

When $\alpha$ = 1, the negative binomial distribution takes the form of a
geometric distribution, which is the discrete correlate of the continuous negative
exponential distribution. 
The negative binomial distribution with $\alpha$ = 0 is Poisson.
As the mean increases, the probability of
a zero decreases, and the more the shape approximates a Gaussian distribution.
As the Poisson mean gets larger it approaches normality, the negative binomial distribution does not respond to larger mean values in that manner. 


The binomial distribution describes the number of r successes in n trials.

The geometric distribution describes the number of failures before the first success, r.

The negative binomial distribution describes the number of failures before the rth success. (Hilbe page 194)

Confusingly, the term ‘dispersion parameter’ can refer to either k or $\alpha$ ; other terms for k include ‘shape
parameter’ and ‘clustering coefficient’.

The only restriction placed on  $\alpha$ is that it take positive rational values,
rarely above 4 (Hilbe page 190)

 

Underdispersed data are assigned the minimum value of $\alpha$, corresponding to k going to infinity.



Accordingly, all calculations in this study were conducted using $\alpha$, but all results and discussion
are posed in terms of k?

In this study ML estimation was conducted for the parameter $\alpha$,
but results are reported in terms of k = 1/ $\alpha$ because k is more
familiar to epidemiologists and ecologists. Estimates of $\alpha$ were
restricted to positive values, because the allowed range for k was (0,infinity). 


file:///C:/Users/Lenovo/OneDrive/Documents/PAPERS/COUNT%20DATA/TRISTAN%20study%20Keene%202007.pdf
thy dispersion is alpha in this paper example figure 1

 The larger the gamma shape parameter, the more dispersed is the distribution
 
 The dispersion parameter k is commonly used as an inverse measure of aggregation in biological count data




References
====
 
``` 
 
    https://stackoverflow.com/questions/52225348/shiny-flexdashboard-reference-object-in-new-tabset#52225733
    https://stats.stackexchange.com/questions/71194/fitting-a-poisson-distribution-with-lme4-and-nlme
    https://stats.stackexchange.com/questions/27869/fitting-a-poisson-glm-mixed-model-with-a-random-slope-and-intercept
    https://stackoverflow.com/questions/6044800/adding-greek-character-to-axis-title

